# Difference between Natural language processing and Word embedding

> Natural language processing (NLP) systems traditionally encode words as strings, which are arbitrary and provide no useful information to the system regarding the relationships that may exist between different words. Word embedding is an alternative technique in NLP, whereby words or phrases from the vocabulary are mapped to vectors of real numbers in a low-dimensional space relative to the vocabulary size, and the similarities between the vectors correlate with the words’ semantic similarity.

From [Lior Shkiller](https://www.oreilly.com/learning/capturing-semantic-meanings-using-deep-learning?imm_mid=0e9900&cmp=em-data-na-na-newsltr_20161019)